errors = errorData$predictionError^2;
hist(errors, breaks=100)
boxplot(errors)
summary(errors)
# Init vars
data = c();
# Build linear model
errorsLm = lm(errors ~ c(1:length(errors)))
data$coefA = errorsLm$coefficients[[1]];
data$coefB = errorsLm$coefficients[[2]];
# Show summary
summary(errors)
data$totalError = sum(errors);
data$meanError  = mean(errors);
data$maxError   = max(errors);
data$minError   = min(errors);
data$success    = length(errors[errors < 0.25]);
data$successPer = data$success / length(errors);
# Plot data and linear model
#par(mfrow=c(1,1), mar=c(1,1,1,1))
plot.ts(errors, type="c");
abline(errorsLm, col="red");
# Finally, print data
print(data);
plot.ts(errors, type="c", col="#00000033");
abline(errorsLm, col="red");
plot.ts(errors, type="o", col="#00000033");
abline(errorsLm, col="red");
plot.ts(errors, type="o", col="#00000033");
plot.ts(errors, type="o", col="#00000011");
abline(errorsLm, col="red");
plot.ts(errors, type="o", col="#00000022");
abline(errorsLm, col="red");
result <- dbSendQuery(db, "SELECT id, predictionError FROM stats_raw WHERE predictionError IS NOT NULL LIMIT 100000");
errorData = dbFetch(result, n=-1)
# Square error
errors = controlData$stdError^2;
hist(errors, breaks=100)
boxplot(errors)
summary(errors)
# Init vars
data = c();
# Build linear model
errorsLm = lm(errors ~ c(1:length(errors)))
data$coefA = errorsLm$coefficients[[1]];
data$coefB = errorsLm$coefficients[[2]];
# Show summary
summary(errors)
data$totalError = sum(errors);
data$meanError  = mean(errors);
data$maxError   = max(errors);
data$minError   = min(errors);
data$success    = length(errors[errors < 0.25]);
data$successPer = data$success / length(errors);
# Plot data and linear model
#par(mfrow=c(1,1), mar=c(1,1,1,1))
plot.ts(errors, type="o", col="#00000022");
abline(errorsLm, col="red");
# Finally, print data
print(data);
result <- dbSendQuery(db, "SELECT id, predictionError FROM stats_raw WHERE predictionError IS NOT NULL LIMIT 100000");
errorData = dbFetch(result, n=-1)
# Square error
errors = controlData$stdError^2;
errors = errorData$predictionError^2;
hist(errors, breaks=100)
boxplot(errors)
summary(errors)
# Init vars
data = c();
# Build linear model
errorsLm = lm(errors ~ c(1:length(errors)))
data$coefA = errorsLm$coefficients[[1]];
data$coefB = errorsLm$coefficients[[2]];
# Show summary
summary(errors)
data$totalError = sum(errors);
data$meanError  = mean(errors);
data$maxError   = max(errors);
data$minError   = min(errors);
data$success    = length(errors[errors < 0.25]);
data$successPer = data$success / length(errors);
# Plot data and linear model
#par(mfrow=c(1,1), mar=c(1,1,1,1))
plot.ts(errors, type="o", col="#00000022");
abline(errorsLm, col="red");
# Finally, print data
print(data);
plot.ts(errors, type="o", col="#00000033");
abline(errorsLm, col="red");
# Finally, print data
print(data);
plot.ts(errors, type="o", col="#00000033");
result <- dbSendQuery(db, "SELECT actualRetweetsRatio, actualFavoritesRatio, actualClicksRatio, actualImpactRatio FROM stats_raw WHERE 1 LIMIT 100000");
controlData = dbFetch(result, n=-1)
#controlData$avgImpact = controlData$actualRetweetsRatio + controlData$actualFavoritesRatio + controlData$actualClicksRatio
controlData$avgImpact = controlData$actualImpactRatio
meanAvgImpact = mean(controlData$avgImpact)
controlData$stdError  = (controlData$avgImpact - meanAvgImpact)
errors = controlData$stdError^2;
hist(errors, breaks=100)
boxplot(errors)
summary(errors)
# Init vars
data = c();
# Build linear model
errorsLm = lm(errors ~ c(1:length(errors)))
data$coefA = errorsLm$coefficients[[1]];
data$coefB = errorsLm$coefficients[[2]];
# Show summary
summary(errors)
data$totalError = sum(errors);
data$meanError  = mean(errors);
data$maxError   = max(errors);
data$minError   = min(errors);
data$success    = length(errors[errors < 0.25]);
data$successPer = data$success / length(errors);
# Plot data and linear model
#par(mfrow=c(1,1), mar=c(1,1,1,1))
plot.ts(errors, type="o", col="#00000033");
#abline(errorsLm, col="red");
# Finally, print data
print(data);
plot.ts(errors, type="o", col="#00000033", ylim=c(0, 0.7));
result <- dbSendQuery(db, "SELECT id, predictionError FROM stats_raw WHERE predictionError IS NOT NULL LIMIT 100000");
errorData = dbFetch(result, n=-1)
errors = errorData$predictionError^2;
hist(errors, breaks=100)
boxplot(errors)
summary(errors)
# Init vars
data = c();
# Build linear model
errorsLm = lm(errors ~ c(1:length(errors)))
data$coefA = errorsLm$coefficients[[1]];
data$coefB = errorsLm$coefficients[[2]];
# Show summary
summary(errors)
data$totalError = sum(errors);
data$meanError  = mean(errors);
data$maxError   = max(errors);
data$minError   = min(errors);
data$success    = length(errors[errors < 0.25]);
data$successPer = data$success / length(errors);
# Plot data and linear model
#par(mfrow=c(1,1), mar=c(1,1,1,1))
plot.ts(errors, type="o", col="#00000033", ylim=c(0, 0.7));
#abline(errorsLm, col="red");
# Finally, print data
print(data);
result <- dbSendQuery(db, "SELECT actualRetweetsRatio, actualFavoritesRatio, actualClicksRatio, actualImpactRatio FROM stats_raw WHERE 1 LIMIT 100000");
controlData = dbFetch(result, n=-1)
controlData$avgImpact = controlData$actualRetweetsRatio + controlData$actualFavoritesRatio + controlData$actualClicksRatio
#controlData$avgImpact = controlData$actualImpactRatio
meanAvgImpact = mean(controlData$avgImpact)
controlData$stdError  = (controlData$avgImpact - meanAvgImpact)
# Regular Neural network test
result <- dbSendQuery(db, "SELECT id, predictionError FROM stats_raw WHERE predictionError IS NOT NULL LIMIT 100000");
errorData = dbFetch(result, n=-1)
# Square error
errors = controlData$stdError^2;
hist(errors, breaks=100)
boxplot(errors)
summary(errors)
# Init vars
data = c();
# Build linear model
errorsLm = lm(errors ~ c(1:length(errors)))
data$coefA = errorsLm$coefficients[[1]];
data$coefB = errorsLm$coefficients[[2]];
# Show summary
summary(errors)
data$totalError = sum(errors);
data$meanError  = mean(errors);
data$maxError   = max(errors);
data$minError   = min(errors);
data$success    = length(errors[errors < 0.25]);
data$successPer = data$success / length(errors);
# Plot data and linear model
#par(mfrow=c(1,1), mar=c(1,1,1,1))
plot.ts(errors, type="o", col="#00000033", ylim=c(0, 0.7));
#abline(errorsLm, col="red");
# Finally, print data
print(data);
plot.ts(errors, type="o", col="#00000033", ylim=c(0, 9));
plot.ts(errors, type="o", col="#00000033", ylim=c(0, 7));
plot.ts(controlData$stdError^2, type="o", col="#00000033", ylim=c(0, 7));
plot.ts(errorData$predictionError^2, type="o", col="#00000033", ylim=c(0, 7));
controlError = controlData$stdError^2;
predictionError = controlData$predictionError^2;
plot.ts(controlError, type="o", col="#00000033", ylim=c(0, 7));
plot.ts(predictionError, type="o", col="#00000033", ylim=c(0, 7));
plot.ts(predictionError, type="o", col="#00000033", ylim=c(0, 7));
predictionError = controlData$predictionError^2;
plot.ts(predictionError, type="o", col="#00000033", ylim=c(0, 7));
neuralNetworkError = controlData$predictionError^2;
plot.ts(neuralNetworkError, type="o", col="#00000033", ylim=c(0, 7));
result <- dbSendQuery(db, "SELECT id, predictionError FROM stats_raw WHERE predictionError IS NOT NULL LIMIT 100000");
errorData = dbFetch(result, n=-1)
neuralNetworkError = controlData$predictionError^2;
plot.ts(neuralNetworkError, type="o", col="#00000033", ylim=c(0, 7));
neuralNetworkError
neuralNetworkError = errorData$predictionError^2;
plot.ts(neuralNetworkError, type="o", col="#00000033", ylim=c(0, 7));
result <- dbSendQuery(db, "SELECT id, predictionError FROM stats_raw WHERE predictionError IS NOT NULL LIMIT 100000");
errorData = dbFetch(result, n=-1)
errors = errorData$predictionError;
# Init vars
data = c();
# Show summary
summary(errors)
data$mad  = mean(abs(errors));
print(data);
data$mse  = mean(errors^2);
print(data);
data$mad  = mean(abs(errors));
data$mse  = mean(errors^2);
data$mape = mean(abs(errors / results));
data$pme  = mean(errors / results);
result <- dbSendQuery(db, "SELECT id, actualRetweetsRatio, actualFavoritesRatio, actualClicksRatio, predictionError FROM stats_raw WHERE predictionError IS NOT NULL LIMIT 100000");
dbData  = dbFetch(result, n=-1);
results = controlData$actualRetweetsRatio + controlData$actualFavoritesRatio + controlData$actualClicksRatio;
errors = errorData$predictionError;
# Init vars
data = c();
# Show summary
summary(errors)
data$mad  = mean(abs(errors));
data$mse  = mean(errors^2);
data$mape = mean(abs(errors / results));
data$pme  = mean(errors / results);
print(data);
summary(results);
summary(errors);
summary(results);
dim(errors);
dim(results);
dim(errors);
length(errors);
length(results);
errors / results
data = c();
# Show summary
summary(errors);
summary(results);
data$mad = mean(abs(errors));
data$mse = mean(errors^2);
data$mae = mean(errors);
data$sse = sum(errors^2);
print(data);
data$mad = mean(abs(errors));
data$mse = mean(errors^2);
data$sse = sum(errors^2);
print(data);
data = c();
data$mad = mean(abs(errors));
data$mse = mean(errors^2);
data$sse = sum(errors^2);
print(data);
errors = (results - mean(results));
# Init vars
data = c();
data$mad = mean(abs(errors));
data$mse = mean(errors^2);
data$sse = sum(errors^2);
print(data);
errors = errorData$predictionError;
# Show summary
summary(errors);
summary(results);
# Init vars
data = c();
data$mad = mean(abs(errors));
data$mse = mean(errors^2);
data$sse = sum(errors^2);
print(data);
data$mse = mean(errors^2);
data$sse = sum(errors^2);
data$maxError = max(abs(errors);
data$maxError = max(abs(errors));
print(data);
errors = (results - mean(results));
summary(results);
# Init vars
data = c();
data$mad = mean(abs(errors));
data$mse = mean(errors^2);
data$sse = sum(errors^2);
data$maxError = max(abs(errors));
print(data);
data$mad = mean(abs(errors));
data$mse = mean(errors^2);
data$sse = sum(errors^2);
data$maxError = max(errors^2);
print(data);
errors = errorData$predictionError;
# Show summary
summary(errors);
summary(results);
# Init vars
data = c();
data$mad = mean(abs(errors));
data$mse = mean(errors^2);
data$sse = sum(errors^2);
data$maxError = max(errors^2);
print(data);
(0.1480-0.1987)/0.1987
(0.0574-0.0986)/0.0986
(2651.45-4550.20)/4550.20
(5.7538-7.3601)/7.3601
boxplot(errors)
stdErrors = (results - mean(results));
errors = errorData$predictionError;
boxplot(data.frame(e=errors, s=stdErrors))
boxplot(data.frame(e=errors^2, s=stdErrors^2))
hist(data.frame(e=errors^2, s=stdErrors^2))
boxplot(data.frame(e=errors^2, s=stdErrors^2))
boxplot(data.frame(e=errors, s=stdErrors))
?boxplot
boxplot(data.frame(e=errors, s=stdErrors))
length(errors)
library("plspm")
library("plsdepot")
library("corrplot")
# Load data
setwd("/Users/manuelmhtr/Projects/TweetsImpactPrediction/PLSPM");
list.files("./data")
tweetsRaw = read.csv("./data/tweetsSummary_v4.0newSet.csv")
head(tweetsRaw)
dim(tweetsRaw)
# Filter useless data
# tweets = subset(tweetsRaw, select=-c(id, userIdStr, twitterIdStr, messageIsDirect, postHourOfDay, postDayOfWeek))
# Normalizagin data (Inverting data where higher is worst)
tweets = subset(tweetsRaw, select=c(id))
tweets$messageReach            = (tweetsRaw$messageIsDirect) * tweetsRaw$messageMentionsCount + (1 - tweetsRaw$messageIsDirect) * (tweetsRaw$userFollowersCount) + 1
tweets$messageReachRatio       = 1 - 1 / ((tweets$messageReach / 10000) + 1)
tweets$clicksRatio             = 1 - 1 / ((tweetsRaw$clicksCount / 20) + 1)
tweets$retweetsRatio           = 1 - 1 / ((tweetsRaw$retweetsCount / 10) + 1)
tweets$favoritesRatio          = 1 - 1 / ((tweetsRaw$favoritesCount / 10) + 1)
tweets$userKloutLevel          = tweetsRaw$userKloutScore / 100
tweets$userMozLevel            = tweetsRaw$userMozScore   / 100
tweets$messageHasMedia         = tweetsRaw$messageHasMedia
tweets$userFollowersRatio      = 1 - 1 / ((tweetsRaw$userFollowersCount / 10000) + 1)
tweets$userListedRatio         = 1 - 1 / ((tweetsRaw$userListedCount / 500) + 1)
tweets$userVerified            = tweetsRaw$userVerified
tweets$id = NULL
tweets$impactCount             = tweetsRaw$clicksCount + tweetsRaw$retweetsCount + tweetsRaw$favoritesCount
tweets$impactRatio             = 1 - 1 / ((tweets$impactCount / 10) + 1)
sd(tweets$impactRatio)
# Custom normalization
tweets = subset(tweetsRaw, select=c(id))
tweets$messageReach            = (tweetsRaw$messageIsDirect) * tweetsRaw$messageMentionsCount + (1 - tweetsRaw$messageIsDirect) * (tweetsRaw$userFollowersCount) + 1
tweets$messageReachRatio       = customNormalizationMean(tweets$messageReach)
summary(tweets);
tweets = subset(tweetsRaw, select=c(id))
tweets$messageReach            = (tweetsRaw$messageIsDirect) * tweetsRaw$messageMentionsCount + (1 - tweetsRaw$messageIsDirect) * (tweetsRaw$userFollowersCount) + 1
tweets$messageReachRatio       = 1 - 1 / ((tweets$messageReach / 10000) + 1)
tweets$clicksRatio             = 1 - 1 / ((tweetsRaw$clicksCount / 20) + 1)
tweets$retweetsRatio           = 1 - 1 / ((tweetsRaw$retweetsCount / 10) + 1)
tweets$favoritesRatio          = 1 - 1 / ((tweetsRaw$favoritesCount / 10) + 1)
tweets$userKloutLevel          = tweetsRaw$userKloutScore / 100
tweets$userMozLevel            = tweetsRaw$userMozScore   / 100
tweets$messageHasMedia         = tweetsRaw$messageHasMedia
tweets$userFollowersRatio      = 1 - 1 / ((tweetsRaw$userFollowersCount / 10000) + 1)
tweets$userListedRatio         = 1 - 1 / ((tweetsRaw$userListedCount / 500) + 1)
tweets$userVerified            = tweetsRaw$userVerified
tweets$id = NULL
summary(tweets);
help(prcomp)
tweetsPca = prcomp(tweets, center = TRUE, scale. = TRUE)
tweetsPca$rotation
tweetsRotationAbs[order(-tweetsRotationAbs[,"PC1"]),1]
audience_cols = c(2,6,7,9,10);
plot(nipals(tweets[,audience_cols]), main = "Audience indicators (circle of correlations)", cex.main = 1)
# 2: favoritesRatio, retweetsRatio, clicksRatio
tweetsRotationAbs[order(-tweetsRotationAbs[,"PC2"]),2]
impact_cols = c(3,4,5);
impact_cols = c(13);
plot(nipals(tweets[,impact_cols]), main = "Impact indicators (circle of correlations)", cex.main = 1)
# 3: messageHasMedia, userVerified
tweetsRotationAbs[order(-tweetsRotationAbs[,"PC3"]),3]
messageContent_cols = c(8,11);
plot(nipals(tweets[,messageContent_cols]), main = "Message content indicators (circle of correlations)", cex.main = 1)
# Building inner model
MessageContent = c(0, 0, 0);
Audience       = c(0, 0, 0);
Impact         = c(1, 1, 0);
# Matrix created by row binding
tweetsInner = rbind(MessageContent, Audience, Impact)
colnames(tweetsInner) = rownames(tweetsInner)
# plot the inner matrix
innerplot(tweetsInner)
# define list of indicators
tweetsOuter = list(messageContent_cols, audience_cols, impact_cols)
# Tell variables are reflexive or formative
tweetsModes = rep("A", 3)
tweetsPls = plspm(tweets, tweetsInner, tweetsOuter, tweetsModes, maxiter=100)
# Goodness of fit (should be higher than 0.70)
tweetsPls$gof
# summarized results
summary(tweetsPls)
help(prcomp)
tweetsPca = prcomp(tweets, center = TRUE, scale. = TRUE)
tweetsPca$rotation
tweetsRotationAbs = abs(tweetsPca$rotation)
tweetsRotationAbs
plot(tweetsPca, type = "l")
names(tweets)
# GET PRINCIPAL COMPONENTS:
# 1: messageReachRatio, userKloutScore, userMozScore, userFollowersCount, userListedCount,
tweetsRotationAbs[order(-tweetsRotationAbs[,"PC1"]),1]
audience_cols = c(2,6,7,9,10);
plot(nipals(tweets[,audience_cols]), main = "Audience indicators (circle of correlations)", cex.main = 1)
# 2: favoritesRatio, retweetsRatio, clicksRatio
tweetsRotationAbs[order(-tweetsRotationAbs[,"PC2"]),2]
impact_cols = c(3,4,5);
impact_cols = c(13);
plot(nipals(tweets[,impact_cols]), main = "Impact indicators (circle of correlations)", cex.main = 1)
# 3: messageHasMedia, userVerified
tweetsRotationAbs[order(-tweetsRotationAbs[,"PC3"]),3]
messageContent_cols = c(8,11);
plot(nipals(tweets[,messageContent_cols]), main = "Message content indicators (circle of correlations)", cex.main = 1)
# Building inner model
MessageContent = c(0, 0, 0);
Audience       = c(0, 0, 0);
Impact         = c(1, 1, 0);
# Matrix created by row binding
tweetsInner = rbind(MessageContent, Audience, Impact)
colnames(tweetsInner) = rownames(tweetsInner)
# plot the inner matrix
innerplot(tweetsInner)
# define list of indicators
tweetsOuter = list(messageContent_cols, audience_cols, impact_cols)
# Tell variables are reflexive or formative
tweetsModes = rep("A", 3)
tweetsPls = plspm(tweets, tweetsInner, tweetsOuter, tweetsModes, maxiter=100)
tweetsPls = plspm(tweets, tweetsInner, tweetsOuter, tweetsModes, maxiter=100)
library("plspm")
library("plsdepot")
library("corrplot")
# Load data
setwd("/Users/manuelmhtr/Projects/TweetsImpactPrediction/PLSPM");
list.files("./data")
tweetsRaw = read.csv("./data/tweetsSummary_v4.0newSet.csv")
head(tweetsRaw)
dim(tweetsRaw)
# Filter useless data
# tweets = subset(tweetsRaw, select=-c(id, userIdStr, twitterIdStr, messageIsDirect, postHourOfDay, postDayOfWeek))
# Normalizagin data (Inverting data where higher is worst)
tweets = subset(tweetsRaw, select=c(id))
tweets$messageReach            = (tweetsRaw$messageIsDirect) * tweetsRaw$messageMentionsCount + (1 - tweetsRaw$messageIsDirect) * (tweetsRaw$userFollowersCount) + 1
tweets$messageReachRatio       = 1 - 1 / ((tweets$messageReach / 10000) + 1)
tweets$clicksRatio             = 1 - 1 / ((tweetsRaw$clicksCount / 20) + 1)
tweets$retweetsRatio           = 1 - 1 / ((tweetsRaw$retweetsCount / 10) + 1)
tweets$favoritesRatio          = 1 - 1 / ((tweetsRaw$favoritesCount / 10) + 1)
tweets$userKloutLevel          = tweetsRaw$userKloutScore / 100
tweets$userMozLevel            = tweetsRaw$userMozScore   / 100
tweets$messageHasMedia         = tweetsRaw$messageHasMedia
tweets$userFollowersRatio      = 1 - 1 / ((tweetsRaw$userFollowersCount / 10000) + 1)
tweets$userListedRatio         = 1 - 1 / ((tweetsRaw$userListedCount / 500) + 1)
tweets$userVerified            = tweetsRaw$userVerified
tweets$id = NULL
head(tweets, n=6)
dim(tweets)
names(tweets)
tweetsRotationAbs[order(-tweetsRotationAbs[,"PC1"]),1]
audience_cols = c(2,6,7,9,10);
plot(nipals(tweets[,audience_cols]), main = "Audience indicators (circle of correlations)", cex.main = 1)
# 2: favoritesRatio, retweetsRatio, clicksRatio
tweetsRotationAbs[order(-tweetsRotationAbs[,"PC2"]),2]
impact_cols = c(3,4,5);
#impact_cols = c(13);
plot(nipals(tweets[,impact_cols]), main = "Impact indicators (circle of correlations)", cex.main = 1)
# 3: messageHasMedia, userVerified
tweetsRotationAbs[order(-tweetsRotationAbs[,"PC3"]),3]
messageContent_cols = c(8,11);
plot(nipals(tweets[,messageContent_cols]), main = "Message content indicators (circle of correlations)", cex.main = 1)
# Building inner model
MessageContent = c(0, 0, 0);
Audience       = c(0, 0, 0);
Impact         = c(1, 1, 0);
# Matrix created by row binding
tweetsInner = rbind(MessageContent, Audience, Impact)
colnames(tweetsInner) = rownames(tweetsInner)
# plot the inner matrix
innerplot(tweetsInner)
# define list of indicators
tweetsOuter = list(messageContent_cols, audience_cols, impact_cols)
# Tell variables are reflexive or formative
tweetsModes = rep("A", 3)
tweetsPls = plspm(tweets, tweetsInner, tweetsOuter, tweetsModes, maxiter=100)
# Goodness of fit (should be higher than 0.70)
tweetsPls$gof
# summarized results
summary(tweetsPls)
# Show results
tweetsPls
tweetsPls$path_coefs
tweetsPls$inner_model
tweetsPls$inner_summary
plot(tweetsPls)
tweetsPls$crossloadings
plot(tweetsPls, what="loadings")
plot(tweetsPls, what="weights")
tweetsPls
tweetsPls$path_coefs
tweetsPls$inner_model
tweetsPls$inner_summary
plot(tweetsPls)
tweetsPls$crossloadings
summary(tweetsPls)
length(errors)
